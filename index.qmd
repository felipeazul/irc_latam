---
title: "The IRC in Latin America"
format: html
---

```{r}
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(plotly)
library(viridis)
library(showtext)
library(ggdist)
```

::: callout-irc
[📢]{.big-number} In **FY24**, the IRC reached an estimated [331,000]{.big-number} clients across **Latin America**.
:::

### Why an estimate, not a count?

Counting people reached by humanitarian services sounds straightforward. In reality, it rarely is.

The IRC’s first priority is to deliver help, not to collect data or complete paperwork. If someone comes for support but doesn’t wish to share personal details, we don’t turn them away. In emergencies, collecting demographic information can be impractical, even unsafe. We don't insist on it. This means we can't necessarily track whether a given individual who used one service later used another. And because many clients receive more than one type of service—health care, protection, education, or livelihoods—we can't simply add up service counts. That would inflate the total through double-counting.

That does not mean measurement is taken lightly. Instead, the IRC in Latam uses a statistical model built on our Annual Statistics, which track progress across individual services. The model blends these service counts with assumptions about overlap and uncertainty, giving us an estimate of unique clients—and a way to report how confident we are in that number.

The result: **in FY24 the IRC reached around 331,000 people in Latin America**. Statistically, we are 90% confident the true figure lies between 319,000 and 345,000. (This does not yet include people reached through online or mass-media campaigns such as the Signpost project.)

The number is an estimate, but not a guess. It reflects hundreds of thousands of real encounters with people seeking help.

### How has the IRC's reach changed over time?

Since **FY19**, IRC’s presence in Latin America has increased more than **seven-fold**, from **44,000 people** to **331,000**. Starting in 2019, the IRC's footprint was modest, rising to 452,000 in 2022, before tailing off. Today's reach, 331k per year, represents around **900 people receiving a service per day**. Figure 1 shows the sharp rise in client numbers.

#### Figure 1. The IRC's reach in Latin America has grown sevenfold since 2019

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Estimate of the number of clients reach across all countries and service types / sectors, based on IRC Latam's model.The sharp rise reflects expansion across countries and sectors. Figures are the median values generated by the model. Hover over the bars to see the numbers."
#| fig-cap-location: margin
#| fig-width: 7
#| fig-height: 5
#| fig-align: "center"

model_data_05_overlap <- read_csv("data/modeled_data_latam.csv")

#### Load fonts ####
font_add_google(name = "Roboto Mono", family = "Roboto Mono")
font_add_google(name = "Inter", family = "Inter")
showtext_auto()

#### Define formulas ####
format_number <- function(x) {
  if (x >= 1e6) {
    paste0(round(x / 1e6, 1), "M clients")
  } else if (x >= 1e3) {
    paste0(round(x / 1e3, 1), "K clients")
  } else {
    paste0(x, " clients")
  }
}

#### Prepare data ####
results <- model_data_05_overlap %>%
  dplyr::select(
    sim, fy, region, country, edu_f, edu_m, edu_total, health_f = adjusted_health_f,
    health_m = adjusted_health_m, health_total = adjusted_health_total, power_f, power_m, power_total,
    safety_f, safety_m, safety_total, wb_f, wb_m, wb_total, clients_f = total_clients_f,
    clients_m = total_clients_m, clients_total = total_clients
  ) %>%
  pivot_longer(
    cols = edu_f:clients_total,
    names_to = "type",
    values_to = "clients"
  ) %>%
  mutate(fy = factor(fy))

results_median <- results %>%
  bind_rows(
    results %>%
      group_by(sim, fy, region, type) %>%
      summarise(clients = sum(clients, na.rm = TRUE), .groups = "drop") %>%
      mutate(country = "Latin America")  # new label to distinguish these rows
  ) %>%
  group_by(fy, region, country, type) %>%
  summarise(clients = median(clients)) %>%
  separate(
    type,
    into = c("sector", "gender"),
    sep = "_",
    remove = FALSE
  ) %>%
  mutate(
    gender = case_when(
      gender == "f" ~ "Female",
      gender == "m" ~ "Male",
      gender == "total" ~ "Total",
      TRUE ~ gender
    ),
    clients_round = round(clients, digits = 0),
    label = sapply(clients_round, format_number),
    label_num = str_remove(label, " clients")
  ) %>%
  dplyr::select(-type)

# Chart showing a regional time series of client reach
chart_overview <- results_median %>%
  filter(sector == "clients", gender == "Total", country == "Latin America") %>%
  mutate(fill_col = factor(case_when(
    fy == "FY24" ~ "#0052CC",
    TRUE ~ "#00B8D9")
  )) %>%
  ggplot(
    aes(x = factor(fy), y = clients, fill = fill_col,
        text = paste0(fy, "<br>", label)
    )) +
  geom_col(alpha = .7) +
  scale_y_continuous(
    labels = scales::label_number(scale_cut = scales::cut_short_scale(), accuracy = 1),
    expand = expansion(mult = c(.01, .05))
  ) +
  labs(
    x = NULL,
    y = NULL
  ) +
  scale_fill_identity() +
  theme_minimal() +
  theme(
    legend.position = "none", 
    axis.title.y = element_text(family = "Inter", size = 18, margin = margin(t = 15)),
    axis.title.x = element_text(family = "Inter", size = 18, margin = margin(t = 15)),
    axis.text.y = element_text(family = "Inter", size = 12),
    axis.text.x = element_text(family = "Roboto Mono", size = 12)
  )

chart_overview_pp <- ggplotly(chart_overview, tooltip = "text")
chart_overview_pp

```

### Where did this happen?

Much of this increase has come from the expansion of the IRC’s presence across different countries. In particular, IRC began working in Venezuela in FY20. IRC’s work in Ecuador, Peru and Mexico contributed significantly. At the same time, IRC’s work in Colombia and North Central America ramped up considerably during the period.

#### Figure 2. IRC's client growth was driven by geographic expansion?

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Each line shows the estimated clients per country. From FY19 to FY21, North Central America (NCA) was counted as a single country. From FY22 the numbers were separated out. Click legend items toggle countries."
#| fig-width: 7
#| fig-height: 5

# Country totals line chart
chart_lines <- results_median %>%
  filter(sector == "clients", gender == "Total", country != "Latin America") %>%
  mutate(
    Country = country,
    fill_col = case_when(
      country == "Colombia" ~ "#FF5630",
      country == "Ecuador" ~ "#0052CC",
      country == "El Salvador" ~ "#006644",
      country == "Guatemala" ~ "#36B37E",
      country == "Honduras" ~ "#ABF5D1",
      country == "Mexico" ~ "#172B4D",
      country == "NCA" ~ "#00B8D9",
      country == "Peru" ~ "#6554C0",
      country == "Venezuela" ~ "#FFAB00",
      TRUE ~ NA_character_
    )
  ) %>%
  ggplot(
    aes(x = fy, y = clients, colour = Country, group = Country,
        text = paste0(fy, "<br>", label, "<br>", Country)
    )) +
  geom_line(
    linewidth = 1.2,
    alpha = .7
  ) +
  guides(fill = "none") +
  labs(
    x = NULL,
    y = NULL,
    colour = "Country"
  ) +
  scale_y_continuous(
    labels = scales::label_number(scale_cut = scales::cut_short_scale(), accuracy = 1),
    expand = expansion(mult = c(.01, .05))
  ) +
  scale_colour_manual(values = c(
    "Colombia" = "#FF5630",
    "Ecuador" = "#0052CC",
    "El Salvador" = "#006644",
    "Guatemala" = "#36B37E",
    "Honduras" = "#ABF5D1",
    "Mexico" = "#172B4D",
    "NCA" = "#00B8D9",
    "Peru" = "#6554C0",
    "Venezuela" = "#FFAB00"
  )) +
  theme_minimal() +
  theme(
    legend.position = "right",
    axis.title.y = element_text(family = "Inter", size = 18, margin = margin(t = 15)),
    axis.title.x = element_text(family = "Inter", size = 18, margin = margin(t = 15)),
    legend.title = element_blank(),
    axis.text.y = element_text(family = "Inter", size = 12),
    axis.text.x = element_text(family = "Roboto Mono", size = 12),
    legend.text = element_text(family = "Inter", size = 9)
  )

chart_lines_pp <- ggplotly(chart_lines, tooltip = "text")
chart_lines_pp

```

### Can I see more detail by sector and gender?

Yes! The Annual Statistics is a set of more than 400 figures collected yearly across sectors. Using these figures we can break down the client count by sector and gender. Note that not all indicators are collected by gender. Some indicators are just overall service numbers. This is often the case for informational services, or services like vaccinations. In these cases, the statstical model imputes a the figures by gender, based on existing gender ratios at different levels (ie, within a region, within a country, and by sector). Figure 3 shows the median client count across all simulations, divided by sector, with female, male and total values displayed.

#### Figure 3. Most clients received health services, and most were women

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Health represents the largest number of clients for the IRC in Latin America and a majority of services are delivered to women."
#| fig-width: 7
#| fig-height: 4

chart_sector <- results_median %>%
  filter(fy == "FY24", sector != "clients") %>%
  group_by(sector, gender) %>%
  summarise(clients = sum(clients)) %>%
  mutate(
    sector = case_when(
      sector == "edu" ~ "Education",
      sector == "health" ~ "Health",
      sector == "power" ~ "Power",
      sector == "safety" ~ "Safety",
      sector == "wb" ~ "Economic\nwellbeing",
      TRUE ~ sector
    ),
    clients_round = round(clients, digits = 0),
    label = sapply(clients_round, format_number),
    label_num = str_remove(label, " clients"),
    gender = factor(gender, levels = c("Female", "Total", "Male"))
  ) %>%
  ggplot(
    aes(x = sector, y = clients, fill = gender, group = gender,
        text = paste0(sector, "<br>", gender, "<br>", label)
    )) +
  geom_col(
    alpha = .7,
    colour = "white",
    position = position_dodge(width = .5)
  ) +
  scale_y_continuous(
    labels = scales::label_number(scale_cut = scales::cut_short_scale(), accuracy = 1),
    expand = expansion(mult = c(.01, .05))
  ) +
  scale_fill_manual(values = c(
    "Total" = "#0052CC",
    "Female" = "#00B8D9",
    "Male" = "#6554C0"
  )) +
  labs(
    x = NULL,
    y = NULL,
    fill = "Gender"
  ) +
  theme_minimal() +
  theme(
    axis.title.x = element_text(family = "Inter", size = 16, margin = margin(t = 15)),
    axis.text.x = element_text(family = "Inter", size = 12),
    axis.title.y = element_text(family = "Inter", size = 16, margin = margin(b = 15)),
    axis.text.y = element_text(family = "Roboto Mono", size = 12),
    legend.title = element_text(family = "Inter", size = 16, margin = margin(b = 15)),
    legend.text = element_text(family = "Inter", size = 12)
  )

chart_sector_pp <- ggplotly(chart_sector, tooltip = "text")
chart_sector_pp

```

You might be thinking, why don’t the total numbers for each sector add up to the 331,000 clients? That's because the total accounts for double counting between sectors, ie, if a single person uses many services. While the Annual Statistics give a breakdown by indicator and sector, it doesn't account for double-counting between sectors. That's where the model comes into its own, because it models large numbers of scenarios to show what would happen where that overlap is large or small.

### Can you tell me more about how the model works?

Yes! The model doesn’t directly count clients because this would mean collecting data about all people who receive services. We don’t want to create barriers to our services, and some people feel uncomfortable sharing their details. In acute emergencies, it can also be logistically challenging to collect this information. Instead, we count the services provided as part of the Annual Statistics process to estimate the number of clients we served.

Using these data collected, we run statistical simulations to estimate the total number of clients: around 331 thousand in Latin. But we also give a range—our best guess is 331k and we’re 90% confident that the number lies between 319k and 345k.

How does the statistical model work? We perform simulations to account for various uncertainties in the data, like errors in counting services or people receiving multiple services, or cases where we don't collect information on a person's gender. We run the simulation over and over to give us realistic scenarios of the total client count if there are small variations in the underlying data and assumptions. The results give us more confidence in the estimate while factoring in things like measurement error and overlaps between different services.

Figure 4 shows the results of 151 simulations. Each dot represents a different simulation (count them just to be sure!). The blue dot is the central estimate, and the teal ones show a 90% confidence interval. The grey ones are outlier results of the simulations. In other words, they are less likely to be the true value.

Since the simulations are run at a country level, we also have country-by-country estimates.

#### Figure 4. The 151 simulation results of the statistical model

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-cap: "Each dot is a simulation result of the total clients reached."
#| fig-width: 7
#| fig-height: 4
#| fig-align: "center"

results_labelled <- results %>%
  group_by(sim, fy, region, type) %>%
  summarise(clients = sum(clients, na.rm = TRUE), .groups = "drop") %>%
  separate(
    type,
    into = c("sector", "gender"),
    sep = "_",
    remove = FALSE
  ) %>%
  mutate(
    gender = case_when(
      gender == "f" ~ "Female",
      gender == "m" ~ "Male",
      gender == "total" ~ "Total",
      TRUE ~ gender
    ),
    clients_round = round(clients, digits = 0),
    label = sapply(clients_round, format_number),
    label_num = str_remove(label, " clients")
  ) %>%
  dplyr::select(-type) %>%
  filter(sector == "clients", gender == "Total")

dotplot_data <- results_labelled %>%
  filter(fy == "FY24", region == "Latin America", sector == "clients", gender == "Total")

median_estimate <- median(dotplot_data$clients)
max_value <- max(dotplot_data$clients)
binwidth_val <- (max(dotplot_data$clients) - min(dotplot_data$clients)) / 30
#  range_est <- range(plot_data$estimate)
#  dynamic_binwidth <- diff(range_est) / 33

dotplot_data <- dotplot_data %>%
  mutate(
    q05 = quantile(clients, 0.05),
    q95 = quantile(clients, 0.95),
    median = median(clients),
    colour_cat = case_when(
      clients == median ~ "median",
      clients < q05 | clients > q95 ~ "outlier",
      TRUE ~ "middle"
    ),
    colour_cat = factor(colour_cat, levels = c("outlier", "middle", "median")) # draw order
  )

chart_dotplot <- dotplot_data %>%
  ggplot(aes(x = clients, fill = colour_cat, colour = colour_cat)) +
  geom_dotplot(
    alpha = 1,
    method = "histodot",
    dotsize = .8,
    binwidth = binwidth_val,
    stackdir = "centerwhole"
  ) +
  scale_colour_manual(values = c(
    outlier = "grey70",
    middle = "#00B8D9",
    median = "#6554C0"
  )) +
  scale_fill_manual(values = c(
    outlier = "grey70",
    middle = "#00B8D9",
    median = "#6554C0"
  )) +
  labs(x = NULL) +
  scale_x_continuous(
    labels = scales::label_number(scale_cut = scales::cut_short_scale(), accuracy = 1),
    expand = expansion(mult = c(.01, .05))
  ) +
  theme_minimal() +
  theme(
    legend.position = "none", 
    axis.title.y = element_blank(),
    axis.title.x = element_text(family = "Inter", size = 14, margin = margin(t = 15)),
    axis.text.y = element_blank(),
    axis.text.x = element_text(family = "Roboto Mono", size = 12)
  ) +
  annotate(
    "curve", 
    x = median_estimate + 400, 
    y = 0.04, 
    xend = ((median_estimate + max_value) / 2) - ((median_estimate + max_value) / 2) * .002,
    yend = 0.34, 
    color = "grey40", 
    curvature = -.3, 
    arrow = arrow(type = "closed", length = unit(0.2, "inches")),
    lineend = "round", 
    linewidth = 1
  ) +
  annotate(
    "text", 
    x = (median_estimate + max_value) / 2, 
    y = 0.32,
    label = format_number(median_estimate),
    family = "Inter", 
    size = 5,
    color = "grey40",
    hjust = 0, 
    vjust = 0
  )
chart_dotplot

```

So those are the results of the full model for Latin America. But since the Annual Statistics are collected by country, we can also show the results at a country level. Figure 5 shows the range of estimates generated for each country. 

This chart shows the central estimate for each country (the dot) as well as the plausible range of values (the thin line is the 95% confidence interval and the thick line is the 66% confidence interval). The text shows the median, or central estimate (ie, the value shown by the dot).

#### Figure 5. Client reach in FY24 varies by country, with uncertainty ranges shown

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-height: 4
#| fig-align: "center"

model_summary <- results %>%
  separate(
    type,
    into = c("sector", "gender"),
    sep = "_",
    remove = FALSE
  ) %>%
  mutate(
    gender = case_when(
      gender == "f" ~ "Female",
      gender == "m" ~ "Male",
      gender == "total" ~ "Total",
      TRUE ~ gender
    )
  ) %>%
  dplyr::select(-type) %>%
  filter(sector == "clients", gender == "Total", fy == "FY24") %>%
  group_by(country) %>%
  summarise(
    mean_val = mean(clients, na.rm = TRUE),
    median_val = median(clients, na.rm = TRUE),
    q95 = quantile(clients, 0.95, na.rm = TRUE)
  ) %>%
  ungroup() %>%
  mutate(
    country = fct_reorder(country, median_val),
    clients_round = round(median_val, digits = 0),
    label = sapply(clients_round, format_number),
    label_num = str_remove(label, " clients")
  )

chart_dist <- results %>%
  filter(type == "clients_total", fy == "FY24") %>%
  ggplot(aes(x = clients, y = country, fill = country, colour = country)) +
  stat_gradientinterval(
    .width = c(0.66, 0.95),  # Displaying 66% and 95% intervals
    point_interval = median_qi  # Median as the point
    #    colour = "black"
  ) + 
  geom_text(
    data = model_summary,
    aes(x = q95 + 5000, y = country, label = label_num),
    colour = "black", hjust = 0, size = 3.5, family = "Inter"
  ) +
  scale_x_continuous(
    limits = c(0, 140000),
    breaks = c(0, 25000, 50000, 75000, 100000, 125000),
    labels = scales::label_number(scale_cut = scales::cut_short_scale())
  ) +
  scale_colour_manual(values = c(
    "Colombia" = "#FF5630",
    "Ecuador" = "#0052CC",
    "El Salvador" = "#006644",
    "Guatemala" = "#36B37E",
    "Honduras" = "#ABF5D1",
    "Mexico" = "#172B4D",
    "Peru" = "#6554C0",
    "Venezuela" = "#FFAB00"
  )) +
  scale_fill_manual(values = c(
    "Colombia" = "#FF5630",
    "Ecuador" = "#0052CC",
    "El Salvador" = "#006644",
    "Guatemala" = "#36B37E",
    "Honduras" = "#ABF5D1",
    "Mexico" = "#172B4D",
    "Peru" = "#6554C0",
    "Venezuela" = "#FFAB00"
  )) +
  labs(
    x = NULL,
    y = NULL
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text.x = element_text(family = "Roboto Mono", size = 12),
    axis.text.y = element_text(family = "Inter", size = 12)
  )

chart_dist

```

### For those looking for more technical details

The IRC doesn't count each client individually. Instead, we track service deliveries, but we recognise that some clients receive multiple services, which could lead to an overcount. And that we maybe didn’t count everything correctly, which could lead to an undercount. To avoid this, we use a statistical model to simulate different scenarios that account for potential sources of uncertainty.

1. **Uncertainty about the precision of service counts**. We assume there could be small errors in how services are counted. For example, sometimes data collection might be incomplete or inaccurate due to limitations in reporting systems or challenges in fieldwork. There might also be small inconsistencies in the way that data are collected from location to location.
2. **Cases where gender of service recipients isn’t recorded**. In some cases we collect and record demographic data on gender from clients. In others we don’t. We therefore have to estimate this breakdown in that subset of cases.
3. **Uncertainty about the reach of health programming**. This is where we face significant uncertainty. While we know the number of people potentially eligible for health services (the catchment area where we operate), it's difficult to know exactly how many people actually receive them. We also directly count some health services but not all. If someone drops-in for a reproductive health information session, we might not note that down. People might also drop out of programs, move, or not report their participation. To account for this uncertainty, we simulate different scenarios using a statistical approach that helps us estimate the range of potential values for the number of people who were truly reached.
4. **Overlap between service areas**. Since many clients use multiple services (eg, a person might receive both education and health services), we need to account for this overlap. If we simply added up the people receiving each service, we'd risk double-counting the same individuals. Our models simulate how much overlap is likely and adjust for it. In this case, we estimate that around 51% of the total population (on average) may have received more than one type of service. We randomly vary this percentage to get a sense of potential sensitivity of our overall calculations to changes in this percentage.

**Step-by-step model explanation**

- **Step 1. Adjusting service counts.** In Step 1, we adjust the indicator data by factoring in the regional averages for services, smoothing out any large discrepancies. This helps us reduce errors that could arise due to incomplete or inconsistent data across different countries or regions. For example, we use a blending weight to adjust the numbers closer to regional norms, which helps us account for country-specific biases or gaps.
- **Step 2. Estimate gender breakdown where gender was not recorded.** For some indicators we know the male / female breakdown, for others we don't. For each indicator where it's not known we estimate it. This is done by creating a weighted average of three gender ratios: the country gender ratio, the regional ratio and the sector ratio. In each simulation, a random weight is applied to each of these ratios, and the average of those ratios is then used to estimate male and femal clients, per indicator. This means that in each simualtion the gender numbers are diffierent.
- **Step 3. Estimate plausible values for health reach.** In Step 3, we use a logarithmic weighting function to adjust health service reach estimates based on the ratio of directly measured health services to the catchment area. For each simulation, this function compares the health catchment number with the total number of services, and asks the question, are these numbers consistent? The function assigns a weight that determines how much we should rely on observed service counts versus the total population in the catchment area.
    - ⁠Low health presence → The model relies more on observed service counts.
    - High health presence → The model shifts the estimate toward the total population.
- This transformation ensures that service reach estimates don’t unrealistically overshoot when observed counts are high, while still adjusting upward when observed counts are low relative to population size. The use of a logarithmic function is key here because it smoothly scales the weight rather than applying a hard cutoff, ensuring a more gradual transition between low and high service presence scenarios.
- **Step 4.** **Monte Carlo simulations.** Monte Carlo simulations are a technique used to model uncertainty and explore different possible outcomes when there are many uncertain variables. In the context of our model, in Step 4 we use Monte Carlo simulations to generate a wide range of plausible values for our final estimates. Monte Carlo simulations let us explore many different possible scenarios, based on real-world uncertainty, and generate a more accurate and reliable range for the number of clients served.

By combining these methods—adjusting for service count uncertainties, using logarithmic functions to better handle skewed data, and running Monte Carlo simulations to account for uncertainty—we can make more informed estimates and better understand the reach and impact of our services. The simulations give us confidence that the range we report (eg, 319 thousand to 345 thousand) reflects a wide range of possible real-world outcomes, and not just a single estimate.
